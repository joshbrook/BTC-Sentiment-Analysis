{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12330007",
   "metadata": {},
   "source": [
    "# Bitcoin price prediction based on *sentiment analysis* of related tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83a059",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "For our project, we have chosen to use twitter data to perform a sentiment analysis on users opinions about crypto currencies inorder to create a predictive model that relies on the sentiment to predict how different crpyto currencies may behave, or vice versa.\n",
    "\n",
    "## Description\n",
    "We begin the project by collecting our data\n",
    "\n",
    "### Data\n",
    "-----------\n",
    "First, we selected the datasets we would use for the analysis as well as to train and test our models later on. We have chosen the following datasets for our analysis:\n",
    "\n",
    "- Bitcoin_Sentiment Twitter dataset\n",
    "  > We use data from the following source:https://www.kaggle.com/code/alexandrayuliu/bitcoin-tweets-sentiment-analysis/data as it is already sentiment tagged to train and test our model\n",
    "\n",
    "\n",
    "### Research Question \n",
    "We chose to investigate how the price of Bitcoin may be affected by twitter sentiments about the currency based on a sentiment analysis model trained on the sentiment-tagged corpus and a final prediction model based on the sentiment model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd36e86",
   "metadata": {},
   "source": [
    "# Preprocessing of training data\n",
    "\n",
    "#### Only to be run once, with results saved to CSV file for later access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68656d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-05 10:52:04</td>\n",
       "      <td>AT_USER AT_USER AT_USER right here w/ AT_USER ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05 10:52:04</td>\n",
       "      <td>AT_USER AT_USER please donate bitcoin19 donate...</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-05 10:52:06</td>\n",
       "      <td>$sos market cap is 308 million. if they’re min...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-05 10:52:07</td>\n",
       "      <td>bitcoin btc current price (gbp): £34,880 like ...</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05 10:52:26</td>\n",
       "      <td>AT_USER right here w/ AT_USER URL referral cod...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                             tweets  \\\n",
       "0  2021-02-05 10:52:04  AT_USER AT_USER AT_USER right here w/ AT_USER ...   \n",
       "1  2021-02-05 10:52:04  AT_USER AT_USER please donate bitcoin19 donate...   \n",
       "2  2021-02-05 10:52:06  $sos market cap is 308 million. if they’re min...   \n",
       "3  2021-02-05 10:52:07  bitcoin btc current price (gbp): £34,880 like ...   \n",
       "4  2021-02-05 10:52:26  AT_USER right here w/ AT_USER URL referral cod...   \n",
       "\n",
       "    score  \n",
       "0  0.0000  \n",
       "1  0.6597  \n",
       "2  0.0000  \n",
       "3  0.3612  \n",
       "4  0.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sent_tweets = pd.read_csv(\"data/sent-tweets.csv\").drop(columns=['user_location', 'user_description', \n",
    "                                                           'user_followers', 'user_friends',])\n",
    "sent_tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6a101",
   "metadata": {},
   "source": [
    "We chose to not remove the stopwords as Saif et al ( LREC 2014) suggests that it might degrade the quality of the classification.\n",
    "\n",
    "On Stopwords, Filtering and Data Sparsity for Sentiment Analysis of Twitter](http://www.lrec-conf.org/proceedings/lrec2014/pdf/292_Paper.pdf) (Saif et al., LREC 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "840bb740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-05 10:52:04</td>\n",
       "      <td>right here w   referral code</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05 10:52:04</td>\n",
       "      <td>please donate bitcoin donate challenge from ...</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-05 10:52:06</td>\n",
       "      <td>sos market cap is  million. if theyre mining ....</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-05 10:52:07</td>\n",
       "      <td>bitcoin btc current price gbp  like my updates...</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05 10:52:26</td>\n",
       "      <td>right here w   referral code  helpmehelpyou</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                             tweets  \\\n",
       "0  2021-02-05 10:52:04                     right here w   referral code     \n",
       "1  2021-02-05 10:52:04    please donate bitcoin donate challenge from ...   \n",
       "2  2021-02-05 10:52:06  sos market cap is  million. if theyre mining ....   \n",
       "3  2021-02-05 10:52:07  bitcoin btc current price gbp  like my updates...   \n",
       "4  2021-02-05 10:52:26       right here w   referral code  helpmehelpyou    \n",
       "\n",
       "    score  \n",
       "0  0.0000  \n",
       "1  0.6597  \n",
       "2  0.0000  \n",
       "3  0.3612  \n",
       "4  0.0000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# Provide case insensitive data\n",
    "sent_tweets[\"tweets\"]=sent_tweets[\"tweets\"].str.lower().astype(str)\n",
    "\n",
    "# Take out links with or without www\n",
    "sent_tweets[\"tweets\"] = sent_tweets[\"tweets\"].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "sent_tweets[\"tweets\"].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\n",
    "\n",
    "# Take out possible HTML character references \n",
    "sent_tweets[\"tweets\"] = sent_tweets[\"tweets\"].apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "\n",
    "# Take out nonletter characters except for spaces and sentence delimitators\n",
    "sent_tweets[\"tweets\"] = sent_tweets[\"tweets\"].apply(lambda x: re.sub(r\"[^a-z\\s.!?]\", '', x))\n",
    "\n",
    "# Sometimes twitter data has links preprocessed into a reference such as {link}\n",
    "sent_tweets[\"tweets\"] = sent_tweets[\"tweets\"].apply(lambda x: re.sub(r'{link}', '', x))\n",
    "\n",
    "# I noticed the dataset contains at user and url references so we can remove them\n",
    "\n",
    "sent_tweets[\"tweets\"]= sent_tweets[\"tweets\"].str.replace('url', '')\n",
    "sent_tweets[\"tweets\"]= sent_tweets[\"tweets\"].str.replace('atuser', '')\n",
    "\n",
    "sent_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe219793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('bitcoin', 'NN'),\n",
       "  ('btc', 'NN'),\n",
       "  ('current', 'JJ'),\n",
       "  ('price', 'NN'),\n",
       "  ('gbp', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('updates?', 'NN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('tip', 'VB'),\n",
       "  ('me', 'PRP'),\n",
       "  ('at', 'IN'),\n",
       "  ('ldztlqrcxnpnvgfnrbazuqvmrz', 'NN')],\n",
       " 0.3612)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "\n",
    "tweets = list(zip(sent_tweets[\"tweets\"], sent_tweets[\"score\"]))\n",
    "\n",
    "regextk = RegexpTokenizer('\\s+', gaps=True)\n",
    "tweettk = TweetTokenizer()\n",
    "\n",
    "tokens = [(regextk.tokenize(tweet), sentiment) for (tweet, sentiment) in tweets if type(tweet) == str]\n",
    "\n",
    "filtered = []\n",
    "for tweet in tokens:\n",
    "    new = []\n",
    "    for tok in tweet[0]:\n",
    "        if tok != \"AT_USER\" and tok != \"URL\":\n",
    "            new.append(tok)\n",
    "            \n",
    "    filtered.append((new, tweet[1]))\n",
    "\n",
    "tagged = [(nltk.pos_tag(tweet), sentiment) for tweet, sentiment in filtered]\n",
    "\n",
    "tagged[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7e4b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bitcoin',\n",
       "  'btc',\n",
       "  'current',\n",
       "  'price',\n",
       "  'gbp',\n",
       "  'like',\n",
       "  'my',\n",
       "  'update',\n",
       "  'you',\n",
       "  'can',\n",
       "  'tip',\n",
       "  'me',\n",
       "  'at',\n",
       "  'ldztlqrcxnpnvgfnrbazuqvmrz'],\n",
       " 0.3612)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def wn_pos(tag):\n",
    "    \"converts treebank tags into wordbank tags for lemmatization\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    if tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    if tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    if tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    return None\n",
    "\n",
    "lem_tweets = []\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for tweet in tagged:\n",
    "    lemmas = []\n",
    "    \n",
    "    for word, tag in tweet[0]:\n",
    "        wn_tag = wn_pos(tag)\n",
    "        \n",
    "        if word[-1] in string.punctuation:\n",
    "                word = word[:-1]\n",
    "\n",
    "        if wn_pos(tag) is not None:\n",
    "            lemmas.append(lem.lemmatize(word, wn_tag))\n",
    "        else:\n",
    "            lemmas.append(lem.lemmatize(word))\n",
    "                \n",
    "    lem_tweets.append((lemmas, tweet[1]))\n",
    "\n",
    "lemmas = [lem for tweet in lem_tweets for lem in tweet]\n",
    "\n",
    "lem_tweets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8abc6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lem_tweets).to_csv(\"lem_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bbe4c",
   "metadata": {},
   "source": [
    "# End of training data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4fdee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['right', 'here', 'w', 'referral', 'code', '35...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['please', 'donate', 'bitcoin19', 'donate', 'c...</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['$sos', 'market', 'cap', 'be', '308', 'millio...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['bitcoin', 'btc', 'current', 'price', '(gbp)'...</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['right', 'here', 'w', 'referral', 'code', '71...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  ['right', 'here', 'w', 'referral', 'code', '35...     0.0000\n",
       "1  ['please', 'donate', 'bitcoin19', 'donate', 'c...     0.6597\n",
       "2  ['$sos', 'market', 'cap', 'be', '308', 'millio...     0.0000\n",
       "3  ['bitcoin', 'btc', 'current', 'price', '(gbp)'...     0.3612\n",
       "4  ['right', 'here', 'w', 'referral', 'code', '71...     0.0000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"lem_tweets.csv\").drop(columns=\"Unnamed: 0\").rename(columns={\"0\":\"Tweet\", \"1\":\"Sentiment\"})\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "134c6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "train_counts = count.fit_transform(train[\"Tweet\"])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c531e09a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.    , 0.6597, 0.    , ..., 0.    , 0.    , 0.5093]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24164/885327644.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mMNB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sentiment\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mval_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mlabelbin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0.    , 0.6597, 0.    , ..., 0.    , 0.    , 0.5093]),)"
     ]
    }
   ],
   "source": [
    "# not yet implemented - need a regressor here as sentiment tags are on a scale\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB().fit(train_tfidf, train[\"Sentiment\"])\n",
    "\n",
    "val_counts = count.transform(val[\"Tweet\"])\n",
    "val_tfidf = tfidf_transformer.transform(val_counts)\n",
    "\n",
    "mnb_pred = MNB.predict(val_tfidf)\n",
    "\n",
    "MNB_df = pd.DataFrame(zip(val[\"Tweet\"], mnb_pred, val[\"Sentiment\"]), columns=[\"Tweet\", \"Predicted\", \"Actual\"])\n",
    "\n",
    "display(MNB_df)\n",
    "\n",
    "print(\"Sentiment prediction accuracy:\", np.mean(mnb_pred == val[\"Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a77cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
